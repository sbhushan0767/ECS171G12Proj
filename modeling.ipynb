{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in processed data\n",
    "df = pd.read_csv('./datasets/credit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Loan ID  Customer ID  Loan Status  Current Loan Amount  Term  \\\n",
       "0      0.081528     0.594985          1.0             0.004342   1.0   \n",
       "1      0.309318     0.371466          1.0             1.000000   1.0   \n",
       "2      0.467122     0.903985          1.0             0.003365   0.0   \n",
       "3      0.539748     0.312567          0.0             0.001954   1.0   \n",
       "4      0.153657     0.565583          1.0             0.002064   1.0   \n",
       "...         ...          ...          ...                  ...   ...   \n",
       "88860  0.635777     0.429482          1.0             0.004314   1.0   \n",
       "88861  0.769598     0.558257          1.0             0.001466   1.0   \n",
       "88862  0.734902     0.423828          1.0             0.001213   1.0   \n",
       "88863  0.050081     0.972796          1.0             1.000000   1.0   \n",
       "88864  0.082026     0.942814          1.0             1.000000   1.0   \n",
       "\n",
       "       Credit Score  Annual Income  Years in current job  Home Ownership  \\\n",
       "0          0.746988       0.006592                   0.8        0.333333   \n",
       "1          0.939759       0.013024                   0.8        0.666667   \n",
       "2          0.819277       0.004413                   0.3        0.666667   \n",
       "3          0.867470       0.004957                   1.0        0.333333   \n",
       "4          0.873494       0.006693                   0.0        0.333333   \n",
       "...             ...            ...                   ...             ...   \n",
       "88860      0.927711       0.008776                   0.7        0.333333   \n",
       "88861      0.879518       0.008688                   0.6        1.000000   \n",
       "88862      0.801205       0.004149                   0.4        0.333333   \n",
       "88863      0.819277       0.005411                   1.0        0.333333   \n",
       "88864      0.981928       0.006063                   0.6        0.333333   \n",
       "\n",
       "        Purpose  Monthly Debt  Years of Credit History  \\\n",
       "0      0.333333      0.011965                 0.202096   \n",
       "1      0.200000      0.066998                 0.167665   \n",
       "2      0.200000      0.020057                 0.124251   \n",
       "3      0.200000      0.037554                 0.203593   \n",
       "4      0.200000      0.024906                 0.238024   \n",
       "...         ...           ...                      ...   \n",
       "88860  0.200000      0.044728                 0.194611   \n",
       "88861  0.200000      0.011003                 0.131737   \n",
       "88862  0.200000      0.028455                 0.092814   \n",
       "88863  0.200000      0.028066                 0.196108   \n",
       "88864  0.200000      0.028083                 0.239521   \n",
       "\n",
       "       Number of Open Accounts  Number of Credit Problems  \\\n",
       "0                     0.066667                   0.066667   \n",
       "1                     0.226667                   0.066667   \n",
       "2                     0.106667                   0.000000   \n",
       "3                     0.066667                   0.000000   \n",
       "4                     0.160000                   0.066667   \n",
       "...                        ...                        ...   \n",
       "88860                 0.133333                   0.000000   \n",
       "88861                 0.106667                   0.000000   \n",
       "88862                 0.093333                   0.000000   \n",
       "88863                 0.093333                   0.066667   \n",
       "88864                 0.173333                   0.000000   \n",
       "\n",
       "       Current Credit Balance  Maximum Open Credit  Bankruptcies  Tax Liens  \\\n",
       "0                    0.006940             0.000271      0.142857        0.0   \n",
       "1                    0.009063             0.000487      0.000000        0.0   \n",
       "2                    0.007796             0.000251      0.000000        0.0   \n",
       "3                    0.006549             0.000177      0.000000        0.0   \n",
       "4                    0.003716             0.000177      0.142857        0.0   \n",
       "...                       ...                  ...           ...        ...   \n",
       "88860                0.012751             0.000427      0.000000        0.0   \n",
       "88861                0.002648             0.000152      0.000000        0.0   \n",
       "88862                0.002260             0.000214      0.000000        0.0   \n",
       "88863                0.005626             0.000156      0.000000        0.0   \n",
       "88864                0.005445             0.000395      0.000000        0.0   \n",
       "\n",
       "       Delinquent Time  Credit Score Range  \n",
       "0             0.000000                   4  \n",
       "1             0.666667                   5  \n",
       "2             0.000000                   4  \n",
       "3             0.000000                   5  \n",
       "4             0.333333                   5  \n",
       "...                ...                 ...  \n",
       "88860         1.000000                   5  \n",
       "88861         0.000000                   5  \n",
       "88862         0.333333                   4  \n",
       "88863         0.333333                   4  \n",
       "88864         0.000000                   5  \n",
       "\n",
       "[88865 rows x 20 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan ID</th>\n      <th>Customer ID</th>\n      <th>Loan Status</th>\n      <th>Current Loan Amount</th>\n      <th>Term</th>\n      <th>Credit Score</th>\n      <th>Annual Income</th>\n      <th>Years in current job</th>\n      <th>Home Ownership</th>\n      <th>Purpose</th>\n      <th>Monthly Debt</th>\n      <th>Years of Credit History</th>\n      <th>Number of Open Accounts</th>\n      <th>Number of Credit Problems</th>\n      <th>Current Credit Balance</th>\n      <th>Maximum Open Credit</th>\n      <th>Bankruptcies</th>\n      <th>Tax Liens</th>\n      <th>Delinquent Time</th>\n      <th>Credit Score Range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.081528</td>\n      <td>0.594985</td>\n      <td>1.0</td>\n      <td>0.004342</td>\n      <td>1.0</td>\n      <td>0.746988</td>\n      <td>0.006592</td>\n      <td>0.8</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.011965</td>\n      <td>0.202096</td>\n      <td>0.066667</td>\n      <td>0.066667</td>\n      <td>0.006940</td>\n      <td>0.000271</td>\n      <td>0.142857</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.309318</td>\n      <td>0.371466</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.939759</td>\n      <td>0.013024</td>\n      <td>0.8</td>\n      <td>0.666667</td>\n      <td>0.200000</td>\n      <td>0.066998</td>\n      <td>0.167665</td>\n      <td>0.226667</td>\n      <td>0.066667</td>\n      <td>0.009063</td>\n      <td>0.000487</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.467122</td>\n      <td>0.903985</td>\n      <td>1.0</td>\n      <td>0.003365</td>\n      <td>0.0</td>\n      <td>0.819277</td>\n      <td>0.004413</td>\n      <td>0.3</td>\n      <td>0.666667</td>\n      <td>0.200000</td>\n      <td>0.020057</td>\n      <td>0.124251</td>\n      <td>0.106667</td>\n      <td>0.000000</td>\n      <td>0.007796</td>\n      <td>0.000251</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.539748</td>\n      <td>0.312567</td>\n      <td>0.0</td>\n      <td>0.001954</td>\n      <td>1.0</td>\n      <td>0.867470</td>\n      <td>0.004957</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.037554</td>\n      <td>0.203593</td>\n      <td>0.066667</td>\n      <td>0.000000</td>\n      <td>0.006549</td>\n      <td>0.000177</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.153657</td>\n      <td>0.565583</td>\n      <td>1.0</td>\n      <td>0.002064</td>\n      <td>1.0</td>\n      <td>0.873494</td>\n      <td>0.006693</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.024906</td>\n      <td>0.238024</td>\n      <td>0.160000</td>\n      <td>0.066667</td>\n      <td>0.003716</td>\n      <td>0.000177</td>\n      <td>0.142857</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>88860</th>\n      <td>0.635777</td>\n      <td>0.429482</td>\n      <td>1.0</td>\n      <td>0.004314</td>\n      <td>1.0</td>\n      <td>0.927711</td>\n      <td>0.008776</td>\n      <td>0.7</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.044728</td>\n      <td>0.194611</td>\n      <td>0.133333</td>\n      <td>0.000000</td>\n      <td>0.012751</td>\n      <td>0.000427</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>88861</th>\n      <td>0.769598</td>\n      <td>0.558257</td>\n      <td>1.0</td>\n      <td>0.001466</td>\n      <td>1.0</td>\n      <td>0.879518</td>\n      <td>0.008688</td>\n      <td>0.6</td>\n      <td>1.000000</td>\n      <td>0.200000</td>\n      <td>0.011003</td>\n      <td>0.131737</td>\n      <td>0.106667</td>\n      <td>0.000000</td>\n      <td>0.002648</td>\n      <td>0.000152</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>88862</th>\n      <td>0.734902</td>\n      <td>0.423828</td>\n      <td>1.0</td>\n      <td>0.001213</td>\n      <td>1.0</td>\n      <td>0.801205</td>\n      <td>0.004149</td>\n      <td>0.4</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.028455</td>\n      <td>0.092814</td>\n      <td>0.093333</td>\n      <td>0.000000</td>\n      <td>0.002260</td>\n      <td>0.000214</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>88863</th>\n      <td>0.050081</td>\n      <td>0.972796</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.819277</td>\n      <td>0.005411</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.028066</td>\n      <td>0.196108</td>\n      <td>0.093333</td>\n      <td>0.066667</td>\n      <td>0.005626</td>\n      <td>0.000156</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>88864</th>\n      <td>0.082026</td>\n      <td>0.942814</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.981928</td>\n      <td>0.006063</td>\n      <td>0.6</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.028083</td>\n      <td>0.239521</td>\n      <td>0.173333</td>\n      <td>0.000000</td>\n      <td>0.005445</td>\n      <td>0.000395</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>88865 rows Ã— 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Preview data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversample imbalanced dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"Credit Score\", \"Credit Score Range\"]\n",
    "X = df.drop(to_drop, axis = 1)\n",
    "labels = df[\"Credit Score Range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training data has 62205 observation with 18 features\ntest data has 26660 observation with 18 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=1)\n",
    "print('training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
    "print('test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 29650), (1, 29650), (2, 29650), (3, 29650), (4, 29650), (5, 29650)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE for testing set:  0.021029988294929657 \n\nMSE for training set:  0.021345523289041747 \n\nR2 score for testing set:  0.27553826461010467 \n\nR2 score for training set:  0.2653067144074618 \n\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = ['Loan ID', 'Customer ID', 'Credit Score Range', \n",
    "                       'Credit Score'])\n",
    "\n",
    "y = df['Credit Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_pred = LR_model.predict(X_test)\n",
    "y_pred_train = LR_model.predict(X_train)\n",
    "## model evaluation\n",
    "print(\"MSE for testing set: \", mean_squared_error(y_test, y_pred), \"\\n\")\n",
    "print(\"MSE for training set: \", mean_squared_error(y_train, y_pred_train), \"\\n\")\n",
    "## The best R2 score is 1, it can be negative because the model is arbitrarily worse\n",
    "print(\"R2 score for testing set: \", r2_score(y_test, y_pred), \"\\n\")\n",
    "print(\"R2 score for training set: \", r2_score(y_train, y_pred_train), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE for training set:  0.020162179948108053\nMSE for testing set:  0.022782211266669045 \n\nR2 score for training set:  0.3060363041843005\nR2 score for testing set:  0.21517596306748266\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = ['Loan ID', 'Customer ID', 'Credit Score', 'Credit Score Range'])\n",
    "y = df['Credit Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_deg = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_deg, y, test_size=0.3, random_state=1)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train, y_train)\n",
    "y_pred_train = poly_model.predict(X_train)\n",
    "y_pred = poly_model.predict(X_test)\n",
    "\n",
    "print('MSE for training set: ', mean_squared_error(y_train, y_pred_train))\n",
    "print('MSE for testing set: ', mean_squared_error(y_test, y_pred), '\\n')\n",
    "\n",
    "print('R2 score for training set: ', r2_score(y_train, y_pred_train))\n",
    "print('R2 score for testing set: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE for training set:  0.020603843161106285\nMSE for testing set:  0.02049758829160938 \n\nR2 score for training set:  0.29083466247755396\nR2 score for testing set:  0.2938789039351387\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = ['Loan ID', 'Customer ID', 'Credit Score', 'Credit Score Range'])\n",
    "y = df['Credit Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "clf = svm.SVR(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('MSE for training set: ', mean_squared_error(y_train, y_pred_train))\n",
    "print('MSE for testing set: ', mean_squared_error(y_test, y_pred),'\\n')\n",
    "\n",
    "print('R2 score for training set: ', r2_score(y_train, y_pred_train))\n",
    "print('R2 score for testing set: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification report for training set:\n               precision    recall  f1-score   support\n\n           0       0.30      0.52      0.38     29650\n           1       0.27      0.37      0.31     29650\n           2       0.25      0.09      0.13     29650\n           3       0.19      0.02      0.03     29650\n           4       0.32      0.27      0.29     29650\n           5       0.42      0.68      0.52     29650\n\n    accuracy                           0.32    177900\n   macro avg       0.29      0.32      0.28    177900\nweighted avg       0.29      0.32      0.28    177900\n \n\nClassification report for testing set:\n               precision    recall  f1-score   support\n\n           0       0.02      0.41      0.04       155\n           1       0.06      0.40      0.11       467\n           2       0.08      0.07      0.08      1279\n           3       0.20      0.01      0.03      3172\n           4       0.42      0.26      0.32      8856\n           5       0.65      0.68      0.67     12731\n\n    accuracy                           0.43     26660\n   macro avg       0.24      0.31      0.21     26660\nweighted avg       0.48      0.43      0.43     26660\n\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_train = clf.predict(X_resampled)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Classification report for training set:\\n', classification_report(y_resampled, y_pred_train), '\\n')\n",
    "print('Classification report for testing set:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "### Random Forest Classification - Oversampled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification report for training set:\n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     29650\n           1       1.00      1.00      1.00     29650\n           2       1.00      1.00      1.00     29650\n           3       1.00      1.00      1.00     29650\n           4       1.00      1.00      1.00     29650\n           5       1.00      1.00      1.00     29650\n\n    accuracy                           1.00    177900\n   macro avg       1.00      1.00      1.00    177900\nweighted avg       1.00      1.00      1.00    177900\n \n\nClassification report for testing set:\n               precision    recall  f1-score   support\n\n           0       1.00      0.34      0.50       155\n           1       0.95      0.33      0.49       467\n           2       0.89      0.40      0.55      1279\n           3       0.65      0.50      0.57      3172\n           4       0.61      0.63      0.62      8856\n           5       0.75      0.84      0.79     12731\n\n    accuracy                           0.69     26660\n   macro avg       0.81      0.50      0.59     26660\nweighted avg       0.70      0.69      0.69     26660\n\n"
     ]
    }
   ],
   "source": [
    "classifier_RF = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "classifier_RF.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_train = classifier_RF.predict(X_resampled)\n",
    "y_pred = classifier_RF.predict(X_test)\n",
    "\n",
    "## the rsult is got from n_estimators=1000\n",
    "print('Classification report for training set:\\n', classification_report(y_resampled, y_pred_train), '\\n')\n",
    "print('Classification report for testing set:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the hyper-parameter tuning\n",
    "def class_plot(grid, grid_param, title):\n",
    "    scores = [x for x in grid.cv_results_['mean_test_score']]\n",
    "    m_depth = grid_param['max_depth']\n",
    "    n_est = grid_param['n_estimators']\n",
    "    #given a new shape of max_depth array into length of n estimators array without changing the data\n",
    "    scores = np.array(scores).reshape(len(m_depth), len(n_est))\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for ind, i in enumerate(m_depth):\n",
    "        plt.plot(n_est, scores[ind], '-o', label='Max depth' + str(i),)\n",
    "    ax.legend(loc='lower right') #, bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel('n estimator')\n",
    "    plt.ylabel('Mean score')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# get the raw features importance (aggregate all dummies)\n",
    "def raw_feature_importance(importance_dataframe, num_pos, cate_list):\n",
    "    # numercial feature importance\n",
    "    num_importance = importance_dataframe.head(num_pos) \n",
    "    num_importance.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    cate_dict ={}\n",
    "    for i in cate_list:\n",
    "        summ = 0\n",
    "        for (idx, row) in importance_dataframe.iterrows():\n",
    "            if i in row.loc['Feature']:\n",
    "                summ += row.loc['Importance']\n",
    "        cate_dict[i] = summ \n",
    "    \n",
    "    cate_importance = pd.DataFrame.from_dict(cate_dict, orient='index')\n",
    "    cate_importance.rename(columns={0: 'Importance'}, inplace=True)\n",
    "    cate_importance.reset_index(inplace = True)\n",
    "    cate_importance.rename(index=str, columns={\"index\": \"Feature\"}, inplace = True)\n",
    "\n",
    "    raw_feature_importances = pd.concat([num_importance, cate_importance])\n",
    "    raw_feature_importances.sort_values(by=['Importance'], inplace = True, ascending=False)\n",
    "    return raw_feature_importances\n",
    "\n",
    "# feature importance\n",
    "def plot_feature_importance(rank_importance,left_limit, color, alpha, size_L, size_H, title):\n",
    "    fig, ax = plt.subplots(1,1) \n",
    "    ax.bar(range(len(rank_importance['Feature'][0:left_limit])),rank_importance[0:left_limit]['Importance'],color=color,alpha=alpha)\n",
    "    ax.set_xticks(range(rank_importance[0:left_limit].shape[0]))\n",
    "    ax.set_xticklabels(rank_importance[0:left_limit]['Feature'], rotation='vertical', fontsize=12)    \n",
    "    ax.set_xlabel('Features', fontsize = 16)\n",
    "    ax.set_ylabel('Feature importance', fontsize = 16)\n",
    "    ax.set_title(title, fontsize = 16)\n",
    "    fig.set_size_inches(size_L, size_H)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestRegressor(n_jobs=6, random_state=1,\n",
       "                                             verbose=1),\n",
       "             param_grid={'max_depth': [30, 40, 45, 50],\n",
       "                         'n_estimators': [2, 5, 10, 15]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_1 = {'n_estimators': [2, 5,10,15],\n",
    "          'max_depth': [30,40,45, 50]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1, verbose=1,n_jobs =6)\n",
    "#The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\n",
    "grid_rf = GridSearchCV(rf, grid_1, cv=3)\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_plot(grid_rf, grid_1, 'RF_CV_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'n_estimators': 15}\n",
      "0.40062378722281666\n"
     ]
    }
   ],
   "source": [
    "print (grid_rf.best_params_)\n",
    "print (grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# re-train the model with full training set\n",
    "rf_best = grid_rf.best_estimator_\n",
    "rf_best.fit(X_train, y_train)\n",
    "pred_rf_test = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44277060973423465"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89895569 0.89820303 0.90467118 0.92703923 0.96455452]\n",
      "Model accuracy of Random Forest Classfier is 0.9186847304544171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "classifier_RF = RandomForestClassifier()\n",
    "cv_score = model_selection.cross_val_score(classifier_RF, X_resampled, y_resampled, cv=5)\n",
    "print(cv_score)\n",
    "print('Model accuracy of Random Forest Classfier' + ' is ' + str(cv_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'n_estimators': [40, 60, 80]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find optimal hyperparameters of Random forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'n_estimators' : [40,60,80]\n",
    "}\n",
    "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
    "Grid_RF.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9180543795277071\n",
      "Best parameters set:\n",
      "n_estimators:80\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_metrics(Grid_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Grid_RF' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d7001aec99ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbest_RF_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGrid_RF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# calculate accuracy, precision and recall, [[tn, fp],[]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcal_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Grid_RF' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "best_RF_model = Grid_RF.best_estimator_\n",
    "# calculate accuracy, precision and recall, [[tn, fp],[]]\n",
    "def cal_evaluation(classifier, cm):\n",
    "    tn = cm[0][0]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    tp = cm[1][1]\n",
    "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
    "    precision = tp / (tp + fp + 0.0)\n",
    "    recall = tp / (tp + fn + 0.0)\n",
    "    print (classifier)\n",
    "    print (\"Accuracy is: \" + str(accuracy))\n",
    "    print (\"precision is: \" + str(precision))\n",
    "    print (\"recall is: \" + str(recall))\n",
    "    print ()\n",
    "# print out confusion matrices\n",
    "def draw_confusion_matrices(confusion_matricies):\n",
    "    class_names = ['Not','Churn']\n",
    "    for cm in confusion_matrices:\n",
    "        classifier, cm = cm[0], cm[1]\n",
    "        cal_evaluation(classifier, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7d7bbeccd030>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forest\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_RF_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdraw_confusion_matrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrices = [ (\"Random Forest\", confusion_matrix(y_test,best_RF_model.predict(X_test)))]\n",
    "draw_confusion_matrices(confusion_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}