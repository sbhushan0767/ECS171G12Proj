{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in processed data\n",
    "df = pd.read_csv('./datasets/credit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Loan ID  Customer ID  Loan Status  Current Loan Amount  Term  \\\n",
       "0      0.081528     0.594985          1.0             0.004342   1.0   \n",
       "1      0.309318     0.371466          1.0             1.000000   1.0   \n",
       "2      0.467122     0.903985          1.0             0.003365   0.0   \n",
       "3      0.539748     0.312567          0.0             0.001954   1.0   \n",
       "4      0.153657     0.565583          1.0             0.002064   1.0   \n",
       "...         ...          ...          ...                  ...   ...   \n",
       "78645  0.635777     0.429482          1.0             0.004314   1.0   \n",
       "78646  0.769598     0.558257          1.0             0.001466   1.0   \n",
       "78647  0.734902     0.423828          1.0             0.001213   1.0   \n",
       "78648  0.050081     0.972796          1.0             1.000000   1.0   \n",
       "78649  0.082026     0.942814          1.0             1.000000   1.0   \n",
       "\n",
       "       Credit Score  Annual Income  Years in current job  Home Ownership  \\\n",
       "0          0.746988       0.006592                   0.8             0.0   \n",
       "1          0.939759       0.013024                   0.8             0.5   \n",
       "2          0.819277       0.004413                   0.3             0.5   \n",
       "3          0.867470       0.004957                   1.0             0.0   \n",
       "4          0.873494       0.006693                   0.0             0.0   \n",
       "...             ...            ...                   ...             ...   \n",
       "78645      0.927711       0.008776                   0.7             0.0   \n",
       "78646      0.879518       0.008688                   0.6             1.0   \n",
       "78647      0.801205       0.004149                   0.4             0.0   \n",
       "78648      0.819277       0.005411                   1.0             0.0   \n",
       "78649      0.981928       0.006063                   0.6             0.0   \n",
       "\n",
       "        Purpose  Monthly Debt  Years of Credit History  \\\n",
       "0      0.416667      0.011965                 0.202096   \n",
       "1      0.250000      0.066998                 0.167665   \n",
       "2      0.250000      0.020057                 0.124251   \n",
       "3      0.250000      0.037554                 0.203593   \n",
       "4      0.250000      0.024906                 0.238024   \n",
       "...         ...           ...                      ...   \n",
       "78645  0.250000      0.044728                 0.194611   \n",
       "78646  0.250000      0.011003                 0.131737   \n",
       "78647  0.250000      0.028455                 0.092814   \n",
       "78648  0.250000      0.028066                 0.196108   \n",
       "78649  0.250000      0.028083                 0.239521   \n",
       "\n",
       "       Number of Open Accounts  Have had Credit Problems  \\\n",
       "0                     0.066667                       1.0   \n",
       "1                     0.226667                       1.0   \n",
       "2                     0.106667                       0.0   \n",
       "3                     0.066667                       0.0   \n",
       "4                     0.160000                       1.0   \n",
       "...                        ...                       ...   \n",
       "78645                 0.133333                       0.0   \n",
       "78646                 0.106667                       0.0   \n",
       "78647                 0.093333                       0.0   \n",
       "78648                 0.093333                       1.0   \n",
       "78649                 0.173333                       0.0   \n",
       "\n",
       "       Current Credit Balance  Maximum Open Credit  \\\n",
       "0                    0.006940             0.000271   \n",
       "1                    0.009063             0.000487   \n",
       "2                    0.007796             0.000251   \n",
       "3                    0.006549             0.000177   \n",
       "4                    0.003716             0.000177   \n",
       "...                       ...                  ...   \n",
       "78645                0.012751             0.000427   \n",
       "78646                0.002648             0.000152   \n",
       "78647                0.002260             0.000214   \n",
       "78648                0.005626             0.000156   \n",
       "78649                0.005445             0.000395   \n",
       "\n",
       "       Have had Bankruptcy before  Have had Tax Liens  Delinquent Time  \\\n",
       "0                             1.0                 0.0         0.000000   \n",
       "1                             0.0                 0.0         0.666667   \n",
       "2                             0.0                 0.0         0.000000   \n",
       "3                             0.0                 0.0         0.000000   \n",
       "4                             1.0                 0.0         0.333333   \n",
       "...                           ...                 ...              ...   \n",
       "78645                         0.0                 0.0         1.000000   \n",
       "78646                         0.0                 0.0         0.000000   \n",
       "78647                         0.0                 0.0         0.333333   \n",
       "78648                         0.0                 0.0         0.333333   \n",
       "78649                         0.0                 0.0         0.000000   \n",
       "\n",
       "      Credit Score Range  \n",
       "0         (701.2, 717.8]  \n",
       "1         (734.4, 751.0]  \n",
       "2         (717.8, 734.4]  \n",
       "3         (717.8, 734.4]  \n",
       "4         (717.8, 734.4]  \n",
       "...                  ...  \n",
       "78645     (734.4, 751.0]  \n",
       "78646     (717.8, 734.4]  \n",
       "78647     (717.8, 734.4]  \n",
       "78648     (717.8, 734.4]  \n",
       "78649     (734.4, 751.0]  \n",
       "\n",
       "[78650 rows x 20 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan ID</th>\n      <th>Customer ID</th>\n      <th>Loan Status</th>\n      <th>Current Loan Amount</th>\n      <th>Term</th>\n      <th>Credit Score</th>\n      <th>Annual Income</th>\n      <th>Years in current job</th>\n      <th>Home Ownership</th>\n      <th>Purpose</th>\n      <th>Monthly Debt</th>\n      <th>Years of Credit History</th>\n      <th>Number of Open Accounts</th>\n      <th>Have had Credit Problems</th>\n      <th>Current Credit Balance</th>\n      <th>Maximum Open Credit</th>\n      <th>Have had Bankruptcy before</th>\n      <th>Have had Tax Liens</th>\n      <th>Delinquent Time</th>\n      <th>Credit Score Range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.081528</td>\n      <td>0.594985</td>\n      <td>1.0</td>\n      <td>0.004342</td>\n      <td>1.0</td>\n      <td>0.746988</td>\n      <td>0.006592</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.011965</td>\n      <td>0.202096</td>\n      <td>0.066667</td>\n      <td>1.0</td>\n      <td>0.006940</td>\n      <td>0.000271</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>(701.2, 717.8]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.309318</td>\n      <td>0.371466</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.939759</td>\n      <td>0.013024</td>\n      <td>0.8</td>\n      <td>0.5</td>\n      <td>0.250000</td>\n      <td>0.066998</td>\n      <td>0.167665</td>\n      <td>0.226667</td>\n      <td>1.0</td>\n      <td>0.009063</td>\n      <td>0.000487</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>(734.4, 751.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.467122</td>\n      <td>0.903985</td>\n      <td>1.0</td>\n      <td>0.003365</td>\n      <td>0.0</td>\n      <td>0.819277</td>\n      <td>0.004413</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>0.250000</td>\n      <td>0.020057</td>\n      <td>0.124251</td>\n      <td>0.106667</td>\n      <td>0.0</td>\n      <td>0.007796</td>\n      <td>0.000251</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>(717.8, 734.4]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.539748</td>\n      <td>0.312567</td>\n      <td>0.0</td>\n      <td>0.001954</td>\n      <td>1.0</td>\n      <td>0.867470</td>\n      <td>0.004957</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.037554</td>\n      <td>0.203593</td>\n      <td>0.066667</td>\n      <td>0.0</td>\n      <td>0.006549</td>\n      <td>0.000177</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>(717.8, 734.4]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.153657</td>\n      <td>0.565583</td>\n      <td>1.0</td>\n      <td>0.002064</td>\n      <td>1.0</td>\n      <td>0.873494</td>\n      <td>0.006693</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.024906</td>\n      <td>0.238024</td>\n      <td>0.160000</td>\n      <td>1.0</td>\n      <td>0.003716</td>\n      <td>0.000177</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>(717.8, 734.4]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78645</th>\n      <td>0.635777</td>\n      <td>0.429482</td>\n      <td>1.0</td>\n      <td>0.004314</td>\n      <td>1.0</td>\n      <td>0.927711</td>\n      <td>0.008776</td>\n      <td>0.7</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.044728</td>\n      <td>0.194611</td>\n      <td>0.133333</td>\n      <td>0.0</td>\n      <td>0.012751</td>\n      <td>0.000427</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>(734.4, 751.0]</td>\n    </tr>\n    <tr>\n      <th>78646</th>\n      <td>0.769598</td>\n      <td>0.558257</td>\n      <td>1.0</td>\n      <td>0.001466</td>\n      <td>1.0</td>\n      <td>0.879518</td>\n      <td>0.008688</td>\n      <td>0.6</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>0.011003</td>\n      <td>0.131737</td>\n      <td>0.106667</td>\n      <td>0.0</td>\n      <td>0.002648</td>\n      <td>0.000152</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>(717.8, 734.4]</td>\n    </tr>\n    <tr>\n      <th>78647</th>\n      <td>0.734902</td>\n      <td>0.423828</td>\n      <td>1.0</td>\n      <td>0.001213</td>\n      <td>1.0</td>\n      <td>0.801205</td>\n      <td>0.004149</td>\n      <td>0.4</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.028455</td>\n      <td>0.092814</td>\n      <td>0.093333</td>\n      <td>0.0</td>\n      <td>0.002260</td>\n      <td>0.000214</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>(717.8, 734.4]</td>\n    </tr>\n    <tr>\n      <th>78648</th>\n      <td>0.050081</td>\n      <td>0.972796</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.819277</td>\n      <td>0.005411</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.028066</td>\n      <td>0.196108</td>\n      <td>0.093333</td>\n      <td>1.0</td>\n      <td>0.005626</td>\n      <td>0.000156</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>(717.8, 734.4]</td>\n    </tr>\n    <tr>\n      <th>78649</th>\n      <td>0.082026</td>\n      <td>0.942814</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.981928</td>\n      <td>0.006063</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.028083</td>\n      <td>0.239521</td>\n      <td>0.173333</td>\n      <td>0.0</td>\n      <td>0.005445</td>\n      <td>0.000395</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>(734.4, 751.0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>78650 rows Ã— 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Preview data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversample imbalanced dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[[\"Credit Score Range\"]] = df[[\"Credit Score Range\"]].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"Credit Score\", \"Credit Score Range\"]\n",
    "X = df.drop(to_drop, axis = 1)\n",
    "labels = df[\"Credit Score Range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training data has 58987 observation with 18 features\ntest data has 19663 observation with 18 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=1)\n",
    "print('training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
    "print('test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 21423), (1, 21423), (2, 21423), (3, 21423), (4, 21423), (5, 21423), (6, 21423), (7, 21423), (8, 21423), (9, 21423)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE for testing set:  0.020731413694460413 \n\nMSE for training set:  0.020935968132080082 \n\nR2 score for testing set:  0.2775364684968068 \n\nR2 score for training set:  0.2721337738409869 \n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns = ['Loan ID', 'Customer ID', 'Credit Score Range', \n",
    "                       'Credit Score'])\n",
    "\n",
    "y = df['Credit Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_pred = LR_model.predict(X_test)\n",
    "y_pred_train = LR_model.predict(X_train)\n",
    "## model evaluation\n",
    "print(\"MSE for testing set: \", mean_squared_error(y_test, y_pred), \"\\n\")\n",
    "print(\"MSE for training set: \", mean_squared_error(y_train, y_pred_train), \"\\n\")\n",
    "## The best R2 score is 1, it can be negative because the model is arbitrarily worse\n",
    "print(\"R2 score for testing set: \", r2_score(y_test, y_pred), \"\\n\")\n",
    "print(\"R2 score for training set: \", r2_score(y_train, y_pred_train), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set:  0.02072959867346114\n",
      "MSE for testing set:  0.02084024219386768 \n",
      "\n",
      "R2 score for training set:  0.2762557478125591\n",
      "R2 score for testing set:  0.2756088357369719\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = ['Loan ID', 'Customer ID', 'Credit Score', 'Credit Score Range'])\n",
    "y = df['Credit Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "clf = svm.SVR(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('MSE for training set: ', mean_squared_error(y_train, y_pred_train))\n",
    "print('MSE for testing set: ', mean_squared_error(y_test, y_pred),'\\n')\n",
    "\n",
    "print('R2 score for training set: ', r2_score(y_train, y_pred_train))\n",
    "print('R2 score for testing set: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for training set:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "(584.834, 601.6]       0.00      0.00      0.00       180\n",
      "  (601.6, 618.2]       0.00      0.00      0.00       321\n",
      "  (618.2, 634.8]       0.00      0.00      0.00       495\n",
      "  (634.8, 651.4]       0.00      0.00      0.00      1033\n",
      "  (651.4, 668.0]       0.10      0.00      0.00      2041\n",
      "  (668.0, 684.6]       0.15      0.00      0.00      3346\n",
      "  (684.6, 701.2]       0.16      0.03      0.05      6156\n",
      "  (701.2, 717.8]       0.26      0.05      0.09     11068\n",
      "  (717.8, 734.4]       0.27      0.35      0.30     15171\n",
      "  (734.4, 751.0]       0.45      0.84      0.59     18891\n",
      "\n",
      "        accuracy                           0.38     58702\n",
      "       macro avg       0.14      0.13      0.10     58702\n",
      "    weighted avg       0.29      0.38      0.29     58702\n",
      " \n",
      "\n",
      "Classification report for testing set:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "(584.834, 601.6]       0.00      0.00      0.00        69\n",
      "  (601.6, 618.2]       0.00      0.00      0.00       140\n",
      "  (618.2, 634.8]       0.00      0.00      0.00       243\n",
      "  (634.8, 651.4]       0.00      0.00      0.00       438\n",
      "  (651.4, 668.0]       0.44      0.01      0.02       855\n",
      "  (668.0, 684.6]       0.10      0.00      0.00      1417\n",
      "  (684.6, 701.2]       0.15      0.03      0.05      2640\n",
      "  (701.2, 717.8]       0.22      0.04      0.07      4576\n",
      "  (717.8, 734.4]       0.26      0.34      0.29      6560\n",
      "  (734.4, 751.0]       0.46      0.85      0.59      8221\n",
      "\n",
      "        accuracy                           0.38     25159\n",
      "       macro avg       0.16      0.13      0.10     25159\n",
      "    weighted avg       0.29      0.38      0.29     25159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_train = clf.predict(X_resampled)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Classification report for training set:\\n', classification_report(y_resampled, y_pred_train), '\\n')\n",
    "print('Classification report for testing set:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the hyper-parameter tuning\n",
    "def class_plot(grid, grid_param, title):\n",
    "    scores = [x for x in grid.cv_results_['mean_test_score']]\n",
    "    m_depth = grid_param['max_depth']\n",
    "    n_est = grid_param['n_estimators']\n",
    "    #given a new shape of max_depth array into length of n estimators array without changing the data\n",
    "    scores = np.array(scores).reshape(len(m_depth), len(n_est))\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for ind, i in enumerate(m_depth):\n",
    "        plt.plot(n_est, scores[ind], '-o', label='Max depth' + str(i),)\n",
    "    ax.legend(loc='lower right') #, bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel('n estimator')\n",
    "    plt.ylabel('Mean score')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data has 66648 observation with 18 features\n",
      "test data has 22217 observation with 18 features\n"
     ]
    }
   ],
   "source": [
    "to_drop = [\"Credit Score\", \"Credit Score Range\"]\n",
    "X = df.drop(to_drop, axis = 1)\n",
    "y = df[\"Credit Score\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "print('training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
    "print('test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestRegressor(n_jobs=6, random_state=1,\n",
       "                                             verbose=1),\n",
       "             param_grid={'max_depth': [30, 40, 45, 50],\n",
       "                         'n_estimators': [2, 5, 10, 15]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_1 = {'n_estimators': [2, 5,10,15],\n",
    "          'max_depth': [30,40,45, 50]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1, verbose=1,n_jobs =6)\n",
    "#The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\n",
    "grid_rf = GridSearchCV(rf, grid_1, cv=3)\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_plot(grid_rf, grid_1, 'RF_CV_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 45, 'n_estimators': 15}\n",
      "0.4200172797374851\n"
     ]
    }
   ],
   "source": [
    "print (grid_rf.best_params_)\n",
    "print (grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# re-train the model with full training set\n",
    "rf_best = grid_rf.best_estimator_\n",
    "rf_best.fit(X_train, y_train)\n",
    "pred_rf_test = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4645312013636427"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier(without oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"Credit Score\", \"Credit Score Range\"]\n",
    "X = df.drop(to_drop, axis = 1)\n",
    "labels = df[\"Credit Score Range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data has 66648 observation with 18 features\n",
      "test data has 22217 observation with 18 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=1)\n",
    "print('training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
    "print('test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54006002 0.53225806 0.53548387 0.53980044 0.53912522]\n",
      "Model accuracy of Random Forest Classfier is 0.5373455202648286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "classifier_RF = RandomForestClassifier()\n",
    "cv_score = model_selection.cross_val_score(classifier_RF, X_train, y_train, cv=5)\n",
    "print(cv_score)\n",
    "print('Model accuracy of Random Forest Classfier' + ' is ' + str(cv_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'n_estimators': [40, 60, 80]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find optimal hyperparameters of Random forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'n_estimators' : [40,60,80]\n",
    "}\n",
    "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
    "Grid_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5338793971506606\n",
      "Best parameters set:\n",
      "n_estimators:80\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_metrics(Grid_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "best_RF_model = Grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred_rf = best_RF_model.predict(X_train)\n",
    "ytest_pred_rf = best_RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714542917585632\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, ytest_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for training set:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "(584.834, 601.6]       1.00      1.00      1.00       204\n",
      "  (601.6, 618.2]       1.00      1.00      1.00       383\n",
      "  (618.2, 634.8]       1.00      1.00      1.00       618\n",
      "  (634.8, 651.4]       1.00      1.00      1.00      1201\n",
      "  (651.4, 668.0]       1.00      1.00      1.00      2369\n",
      "  (668.0, 684.6]       1.00      1.00      1.00      3810\n",
      "  (684.6, 701.2]       1.00      1.00      1.00      7061\n",
      "  (701.2, 717.8]       1.00      1.00      1.00     12415\n",
      "  (717.8, 734.4]       1.00      1.00      1.00     17329\n",
      "  (734.4, 751.0]       1.00      1.00      1.00     21258\n",
      "\n",
      "        accuracy                           1.00     66648\n",
      "       macro avg       1.00      1.00      1.00     66648\n",
      "    weighted avg       1.00      1.00      1.00     66648\n",
      " \n",
      "\n",
      "Classification report for testing set:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "(584.834, 601.6]       1.00      0.27      0.42        64\n",
      "  (601.6, 618.2]       1.00      0.29      0.45       122\n",
      "  (618.2, 634.8]       0.94      0.29      0.44       203\n",
      "  (634.8, 651.4]       0.90      0.30      0.45       405\n",
      "  (651.4, 668.0]       0.76      0.35      0.48       788\n",
      "  (668.0, 684.6]       0.69      0.43      0.53      1317\n",
      "  (684.6, 701.2]       0.59      0.46      0.52      2340\n",
      "  (701.2, 717.8]       0.57      0.50      0.53      4138\n",
      "  (717.8, 734.4]       0.47      0.52      0.49      5733\n",
      "  (734.4, 751.0]       0.62      0.77      0.68      7107\n",
      "\n",
      "        accuracy                           0.57     22217\n",
      "       macro avg       0.75      0.42      0.50     22217\n",
      "    weighted avg       0.59      0.57      0.56     22217\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for training set:\\n', classification_report(y_train, ytrain_pred_rf), '\\n')\n",
    "print('Classification report for testing set:\\n', classification_report(y_test, ytest_pred_rf), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance ranking by Random Forest Model:\n",
      "Maximum Open Credit : 0.1062\n",
      "Current Credit Balance : 0.0978\n",
      "Annual Income : 0.0928\n",
      "Monthly Debt : 0.0916\n",
      "Current Loan Amount : 0.0907\n",
      "Years of Credit History : 0.0892\n",
      "Customer ID : 0.0889\n",
      "Loan ID : 0.0885\n",
      "Number of Open Accounts : 0.0668\n",
      "Years in current job : 0.0495\n",
      "Term : 0.0391\n",
      "Purpose : 0.0255\n",
      "Delinquent Time : 0.025\n",
      "Home Ownership : 0.0194\n",
      "Loan Status : 0.012\n",
      "Number of Credit Problems : 0.0084\n",
      "Bankruptcies : 0.006\n",
      "Tax Liens : 0.0024\n"
     ]
    }
   ],
   "source": [
    "#show feature importance\n",
    "importances = best_RF_model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature importance ranking by Random Forest Model:\")\n",
    "for ind in range(X.shape[1]):\n",
    "  print (\"{0} : {1}\".format(X.columns[indices[ind]],round(importances[indices[ind]], 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier( with oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89775614 0.898744   0.90502399 0.92760373 0.96509549]\n",
      "Model accuracy of Random Forest Classfier is 0.9188446702417913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "classifier_RF = RandomForestClassifier()\n",
    "cv_score = model_selection.cross_val_score(classifier_RF, X_resampled, y_resampled, cv=5)\n",
    "print(cv_score)\n",
    "print('Model accuracy of Random Forest Classfier' + ' is ' + str(cv_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'n_estimators': [40, 60, 80]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find optimal hyperparameters of Random forest through grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'n_estimators' : [40,60,80]\n",
    "}\n",
    "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
    "Grid_RF.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9175039984946844\n",
      "Best parameters set:\n",
      "n_estimators:80\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_metrics(Grid_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "best_RF_model = Grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred_rf = best_RF_model.predict(X_resampled)\n",
    "ytest_pred_rf = best_RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5769455822118198\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, ytest_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for training set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     21258\n",
      "           1       1.00      1.00      1.00     21258\n",
      "           2       1.00      1.00      1.00     21258\n",
      "           3       1.00      1.00      1.00     21258\n",
      "           4       1.00      1.00      1.00     21258\n",
      "           5       1.00      1.00      1.00     21258\n",
      "           6       1.00      1.00      1.00     21258\n",
      "           7       1.00      1.00      1.00     21258\n",
      "           8       1.00      1.00      1.00     21258\n",
      "           9       1.00      1.00      1.00     21258\n",
      "\n",
      "    accuracy                           1.00    212580\n",
      "   macro avg       1.00      1.00      1.00    212580\n",
      "weighted avg       1.00      1.00      1.00    212580\n",
      " \n",
      "\n",
      "Classification report for testing set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.30      0.44        64\n",
      "           1       0.87      0.38      0.53       122\n",
      "           2       0.90      0.38      0.53       203\n",
      "           3       0.85      0.39      0.54       405\n",
      "           4       0.67      0.44      0.53       788\n",
      "           5       0.57      0.50      0.53      1317\n",
      "           6       0.55      0.52      0.54      2340\n",
      "           7       0.59      0.54      0.56      4138\n",
      "           8       0.49      0.50      0.50      5733\n",
      "           9       0.63      0.75      0.68      7107\n",
      "\n",
      "    accuracy                           0.58     22217\n",
      "   macro avg       0.70      0.47      0.54     22217\n",
      "weighted avg       0.59      0.58      0.58     22217\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for training set:\\n', classification_report(y_resampled, ytrain_pred_rf), '\\n')\n",
    "print('Classification report for testing set:\\n', classification_report(y_test, ytest_pred_rf), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance ranking by Random Forest Model:\n",
      "Maximum Open Credit : 0.0959\n",
      "Current Credit Balance : 0.0928\n",
      "Monthly Debt : 0.0927\n",
      "Annual Income : 0.0927\n",
      "Customer ID : 0.0912\n",
      "Loan ID : 0.0902\n",
      "Years of Credit History : 0.0895\n",
      "Current Loan Amount : 0.0884\n",
      "Number of Open Accounts : 0.0715\n",
      "Years in current job : 0.0486\n",
      "Term : 0.0367\n",
      "Delinquent Time : 0.0285\n",
      "Purpose : 0.0281\n",
      "Home Ownership : 0.0208\n",
      "Loan Status : 0.0114\n",
      "Number of Credit Problems : 0.0101\n",
      "Bankruptcies : 0.0081\n",
      "Tax Liens : 0.0027\n"
     ]
    }
   ],
   "source": [
    "#show feature importance\n",
    "importances = best_RF_model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature importance ranking by Random Forest Model:\")\n",
    "for ind in range(X.shape[1]):\n",
    "  print (\"{0} : {1}\".format(X.columns[indices[ind]],round(importances[indices[ind]], 4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}