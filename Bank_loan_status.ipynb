{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/183B_W_R2qSnT_JjEUcI3Ny1vH36desCp/view?usp=sharing\n",
    "file1 = drive.CreateFile({'id':'183B_W_R2qSnT_JjEUcI3Ny1vH36desCp'}) # replace the id with id of file you want to access\n",
    "file1.GetContentFile('credit_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/1ceLPls-2L2RuPoAJXAwGgcqxufoHAs0t/view?usp=sharing\n",
    "file2 = drive.CreateFile({'id':'1ceLPls-2L2RuPoAJXAwGgcqxufoHAs0t'}) # replace the id with id of file you want to access\n",
    "file2.GetContentFile('credit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('credit_train.csv')\n",
    "df_test = pd.read_csv('credit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./datasets/credit_train.csv')\n",
    "df_test = pd.read_csv('./datasets/credit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "#non numerica type columns: Loan_ID, Customer ID, Loan Status, Term, Years in Current job, Home Ownership, Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check missing values \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Months since last delinquent'].isna().sum()/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Months since last delinquent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(min(df['Credit Score']))\n",
    "print(max(df['Credit Score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert credit score which value higher than 5000 ten times smaller\n",
    "arr = df['Credit Score'].isnull().values\n",
    "Shape = df.shape\n",
    "for i in range(Shape[0]):\n",
    "    ## skip all na values\n",
    "    if arr[i] == False:\n",
    "        if df['Credit Score'].values[i] > 5000:\n",
    "            tmp = df['Credit Score'].values[i]\n",
    "            tmp = (tmp*10)/100\n",
    "            df['Credit Score'].values[i] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(min(df['Credit Score']))\n",
    "print(max(df['Credit Score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall, we need to impute missing values for all the columns, since missing values for Months since last delinquent take up over 50% \n",
    "from sklearn.impute import SimpleImputer\n",
    "#impute missing values for numerical data : mean\n",
    "# Select numeric columns.\n",
    "numeric = df.select_dtypes('number')\n",
    "# # Select string and object columns.\n",
    "categoric = df.select_dtypes('object')\n",
    "\n",
    "# # # Fill numeric columns with mean.\n",
    "df[numeric.columns] = numeric.fillna(numeric.mean())\n",
    "# # # Fill object columns with mode.\n",
    "df[categoric.columns] = categoric.fillna(categoric.agg(lambda x: x.mode().values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop na\n",
    "# df.dropna(axis=0, inplace=True)\n",
    "# df.reset_index(inplace=True)\n",
    "# df.drop(columns = ['index'], inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check unique values for each column\n",
    "df.nunique()\n",
    "#meaningful columns often have fewer number of unique colunmns\n",
    "#we need to conduct some transformation for those columns which are categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categoric.columns].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature encoding for categorical varaibles\n",
    "#label encoding: convert each value in a column to a number \n",
    "#All the categorical variables except years in current job can be handled with label encoding \n",
    "#Years in current job are required to be transformed into numerical variables\n",
    "#Home ownership and purpose don't have seuqntial characteristic, not use label encoding\n",
    "#create initial categorical dataframe\n",
    "\n",
    "categoric_cols = list(categoric.columns)\n",
    "categoric_cols.remove('Years in current job')\n",
    "categoric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creatin instance of labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[categoric_cols] = df[categoric_cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 'years in current job' to numerical type\n",
    "## Not sure how to convert 10+ years and less than 1 year to numeric type\n",
    "## So I used 0 for less than 1 year, and 10 for 10+ years\n",
    "label = \"Years in current job\"\n",
    "df[label] = df[label].replace({'< 1 year':0, '1 year': 1, '2 years': 2,\n",
    "                                          '3 years':3, '4 years':4, '5 years':5, \n",
    "                                          '6 years':6, '7 years':7, '8 years':8, \n",
    "                                          '9 years': 9, '10+ years': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "### Categorize credit score into differnt ranges"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cs = min(df['Credit Score'])\n",
    "max_cs = max(df['Credit Score'])\n",
    "binSize=6\n",
    "per_bin = (max_cs - min_cs)/binSize\n",
    "\n",
    "bin = []\n",
    "bin.append(min_cs)\n",
    "CS_count = []\n",
    "for i in range(7):\n",
    "    if i == 6:\n",
    "        bin.append(round(max_cs,0))\n",
    "    else:\n",
    "        bin.append(round(bin[i]+per_bin,0))  \n",
    "    if(i < 6):\n",
    "        CS_count.append(0)\n",
    "\n",
    "def label_cs(row):\n",
    "    if bin[0] <= row['Credit Score'] and row['Credit Score'] <= bin[1]:\n",
    "        i = 1\n",
    "        CS_count[i-1] = CS_count[i-1] + 1\n",
    "        return i\n",
    "    elif row['Credit Score'] <= bin[2]:\n",
    "        i = 2\n",
    "        CS_count[i-1] = CS_count[i-1] + 1\n",
    "        return i\n",
    "    elif row['Credit Score'] <= bin[3]:\n",
    "        i = 3\n",
    "        CS_count[i-1] = CS_count[i-1] + 1\n",
    "        return i\n",
    "    elif row['Credit Score'] <= bin[4]:\n",
    "        i = 4\n",
    "        CS_count[i-1] = CS_count[i-1] + 1\n",
    "        return i\n",
    "    elif row['Credit Score'] <= bin[5]:\n",
    "        i = 5\n",
    "        CS_count[i-1] = CS_count[i-1] + 1\n",
    "        return i\n",
    "    elif row['Credit Score'] <= bin[6]:\n",
    "        i = 6\n",
    "        CS_count[i-1] = CS_count[i-1] + 1\n",
    "        return i  \n",
    "df['Credit Score category'] = df.apply(lambda row: label_cs(row),axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    print(\"Range\", i+1, \":\", bin[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_category = pd.DataFrame({\n",
    "   'Population':CS_count, \n",
    "   }, index = ['585 ~ 613', '614 ~ 641','642 ~ 669','670 ~ 697','698 ~ 725', '726 ~ 753'])\n",
    "CS_category.plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check the size of all range\n",
    "total = 0\n",
    "for i in range(6):\n",
    "    total = total + CS_count[i]\n",
    "most = CS_count[4] + CS_count[5]\n",
    "most/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use qq plot to show some distributions of variables\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "import pylab\n",
    "current_credit = df['Current Credit Balance']\n",
    "sm.qqplot(current_credit, line='45')\n",
    "pylab.show()\n",
    "# our QQ plot shows that current loan amount has too many values at the lower end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "import pylab\n",
    "current_loan = df['Current Loan Amount']\n",
    "sm.qqplot(current_loan, line='45')\n",
    "pylab.show()\n",
    "#there are also too many lower end values for current loan amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric.columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct normalization since our dataset is not normally distributed based on our observations\n",
    "# normalization (x-x_min)/(x_max-x_min) \n",
    "#advantge of normalization: \n",
    "#1. improve training process\n",
    "#2. all data are within the same scale\n",
    "#3. logistic regression, SVM requires normalization\n",
    "from sklearn import preprocessing\n",
    "# normalize the continuous variable\n",
    "df_tmp = df.drop(columns = ['Credit Score category'])\n",
    "numeric = df_tmp.select_dtypes('number')\n",
    "numeric_vals = numeric.values#numpy array\n",
    "transformer = preprocessing.MinMaxScaler()\n",
    "numeric_normalized = transformer.fit_transform(numeric_vals)\n",
    "numeric_names = list(numeric.columns)\n",
    "df[numeric_names] = numeric_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## double check na\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"Credit Score\"]\n",
    "X = df.drop(to_drop, axis = 1)\n",
    "y = df[\"Credit Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "print('training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
    "print('test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')"
   ]
  },
  {
   "source": [
    "### Part2: Check features correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.drop(columns = ['Loan ID', 'Customer ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bankruptcies and Number of credit problems have relatively strong positive correlation\n",
    "## Number of credit problems and Tax lien have relatively strong postiive correlation\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df_corr.corr(), annot = True,linewidths=.8, ax=ax)"
   ]
  },
  {
   "source": [
    "Part3:Model training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search to find the optimal hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "X = df.drop(columns = ['Loan ID', 'Customer ID', 'Credit Score category'])\n",
    "y = df['Credit Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_pred = LR_model.predict(X_test)\n",
    "y_pred_train = LR_model.predict(X_train)\n",
    "## model evaluation\n",
    "print(\"MSE for testing set: \", mean_squared_error(y_test, y_pred), \"\\n\")\n",
    "print(\"MSE for training set: \", mean_squared_error(y_train, y_pred_train), \"\\n\")\n",
    "## The best R2 score is 1, it can be negative because the model is arbitrarily worse\n",
    "print(\"R2 score for testing set: \", r2_score(y_test, y_pred), \"\\n\")\n",
    "print(\"R2 score for training set: \", r2_score(y_train, y_pred_train), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = df.drop(columns = ['Loan ID', 'Customer ID', 'Credit Score category'])\n",
    "y = df['Credit Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_deg = X\n",
    "X_deg = poly.fit_transform(X_deg)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_deg, y, test_size=0.3, random_state=1)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train, y_train)\n",
    "y_pred = poly_model.predict(X_test)\n",
    "y_pred_train = poly_model.predict(X_train)\n",
    "## model evaluation\n",
    "print(\"MSE for testing set: \", mean_squared_error(y_test, y_pred), \"\\n\")\n",
    "print(\"MSE for training set: \", mean_squared_error(y_train, y_pred_train), \"\\n\")\n",
    "## The best R2 score is 1, it can be negative because the model is arbitrarily worse\n",
    "print(\"R2 score for testing set: \", r2_score(y_test, y_pred), \"\\n\")\n",
    "print(\"R2 score for training set: \", r2_score(y_train, y_pred_train), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns = ['Loan ID', 'Customer ID','Credit Score category', 'Months since last delinquent'])\n",
    "y = df['Credit Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "clf = svm.SVR(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(\"MSE for testing set: \", mean_squared_error(y_test, y_pred), \"\\n\")\n",
    "print(\"MSE for training set: \", mean_squared_error(y_train, y_pred_train), \"\\n\")\n",
    "print(\"R2 score for testing set: \", r2_score(y_test, y_pred), \"\\n\")\n",
    "print(\"R2 score for training set: \", r2_score(y_train, y_pred_train), \"\\n\")\n",
    "#print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "X = df.drop(columns=['Credit Score','Loan ID', 'Customer ID', 'Credit Score category'])\n",
    "y = df['Credit Score category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "Logis_model = LogisticRegression()\n",
    "Logis_model.fit(X_train, y_train)\n",
    "y_pred = Logis_model.predict(X_test)\n",
    "y_pred_train = Logis_model.predict(X_train)\n",
    "## model evaluation\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "### One-hot encode credit score category for NN model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oneHot = df\n",
    "df_oneHot.head()\n",
    "\n",
    "## one hot encode Credit Score category\n",
    "CSC = df_oneHot['Credit Score category']\n",
    "## One hot encode the \"Credit Score category\" attribute\n",
    "CSC_encoded = pd.get_dummies(CSC, prefix='Credit Score category')\n",
    "## merge the encoded \"Credit Score category\" into the dataset\n",
    "df_oneHot = CSC_encoded.merge(df_oneHot, left_index=True, right_index=True)\n",
    "## Drop the original \"Credit Score category\" column\n",
    "df_oneHot = df_oneHot.drop(columns = ['Credit Score category'])\n",
    "\n",
    "df_oneHot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_oneHot_shorten = df_oneHot.iloc[:10000]\n",
    "df_oneHot_shorten = df_oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers\n",
    "ylabel = ['Credit Score category_1','Credit Score category_2','Credit Score category_3','Credit Score category_4','Credit Score category_5','Credit Score category_6']\n",
    "y = df_oneHot_shorten[ylabel]\n",
    "xlabel = ['Credit Score','Loan ID', 'Customer ID', \n",
    "            'Credit Score category_1','Credit Score category_2','Credit Score category_3',\n",
    "            'Credit Score category_4','Credit Score category_5','Credit Score category_6']\n",
    "X = df_oneHot_shorten.drop(columns = xlabel)\n",
    "\n",
    "# X = df.drop(columns = ['Loan ID', 'Customer ID','Credit Score category'])\n",
    "# y = df['Credit Score']\n",
    "\n",
    "hiddenNodes = 32\n",
    "outputNode = 5\n",
    "epochSize = 100\n",
    "batchSize = 32\n",
    "learningRate = 0.001\n",
    "precision = keras.metrics.Precision(name=\"precision\")\n",
    "recallM = keras.metrics.Recall(name=\"recall\")\n",
    "AUC = keras.metrics.AUC(name=\"auc\")\n",
    "#optimizer = keras.optimizers.SGD(learning_rate=learningRate)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learningRate)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, Xval_test, y_train, yval_test = train_test_split(X, y, test_size=0.3)\n",
    "xval,xtest,yval,ytest = train_test_split(Xval_test,yval_test,test_size = 0.5)\n",
    "\n",
    "input_layer = keras.Input(shape=X.shape)\n",
    "model = Sequential()\n",
    "model.add(tf.keras.Input(shape=X.shape, name=\"input\"))\n",
    "model.add(Dense(hiddenNodes, activation='relu', name=\"hiddenlayer1\"))\n",
    "#model.add(Dense(hiddenNodes, activation='relu', name=\"hiddenlayer2\"))\n",
    "model.add(Dense(outputNode, activation='softmax', name=\"outputlayer\"))\n",
    "# Compile model (required to make predictions)\n",
    "lossFun =  tf.keras.losses.MeanSquaredError()\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy', 'mse', precision, recallM, AUC])\n",
    "\n",
    "\n",
    "modelFit = model.fit(X_train, y_train, validation_data = (xval, yval), \n",
    "                    verbose = 0, epochs=epochSize, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting all the evaluation scores\n",
    "loss, acc, mse, pre, recall, auc = model.evaluate(X_train, y_train, verbose = 0)\n",
    "loss2, acc2, mse2, pre2, recall2, auc2 = model.evaluate(xtest, ytest, verbose = 0)\n",
    "\n",
    "performance_report = pd.DataFrame({\n",
    "   'Loss':[loss,loss2],\n",
    "    'Accuracy':[acc,acc2],\n",
    "    'Precision':[pre,pre2],\n",
    "    'Recall':[recall,recall2],\n",
    "    'MSE':[mse,mse2],\n",
    "    'AUC':[auc,auc2],\n",
    "   }, index=['training set', 'test set'])\n",
    "performance_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "source": [
    "### Create dummy input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function receive user input and then generate a output for model to make a prediction\n",
    "## e.g: model.predict(output)\n",
    "def createDummy(loan_status, cur_loan_amount, term, annual_income, \n",
    "                years_job, home_own, purpose, monthly_debt, years_CH, \n",
    "                month_delinq, num_openAC, num_credit_prob, cur_creditBalance, \n",
    "                max_openCredit, bankrupticies, taxLien):\n",
    "\n",
    "                ## apply min-max scaler on the numeric values\n",
    "                dummy = [cur_loan_amount,0,annual_income,monthly_debt,\n",
    "                        years_CH,month_delinq,num_openAC,num_credit_prob,\n",
    "                        cur_creditBalance,max_openCredit,bankrupticies,taxLien]\n",
    "                dummy = np.reshape(np.array(dummy), (1,12))\n",
    "                dummy = transformer.transform(dummy)\n",
    "\n",
    "                ## generate a final output\n",
    "                output = [loan_status,dummy[0][0], term, dummy[0][2], years_job, home_own, purpose]\n",
    "                for i in range(3,12):\n",
    "                    output.append(dummy[0][i])\n",
    "                ## reshape\n",
    "                output = np.reshape(np.array(output), (1,15))\n",
    "                return output\n",
    "\n",
    "## This function print the category result\n",
    "def getCategory(prediction):\n",
    "    prediction = model.predict(prediction)\n",
    "    max = 0\n",
    "    result = -1\n",
    "    for i in range(6):\n",
    "        if prediction[0][i] >= max:\n",
    "            max = prediction[0][i]\n",
    "            result = i\n",
    "    print(\"Category is: \", result, \"\\n\")\n",
    "    if result == 0:\n",
    "        print(\"Credit Score: 585 ~ 612\\n\")\n",
    "    elif result == 1:\n",
    "        print(\"Credit Score: 613 ~ 640\\n\")\n",
    "    elif result == 2:\n",
    "        print(\"Credit Score: 641 ~ 668\\n\")\n",
    "    elif result == 3:\n",
    "        print(\"Credit Score: 668 ~ 696\\n\")\n",
    "    elif result == 4:\n",
    "        print(\"Credit Score: 697 ~ 723\\n\")\n",
    "    else:\n",
    "        print(\"Credit Score: 724 ~ 751\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## enter data to make a prediction\n",
    "output = []\n",
    "\n",
    "loan_status = 1\n",
    "cur_loan_amount = 440000\n",
    "term = 1\n",
    "annual_income= 1234567\n",
    "years_in_current_job = 7\n",
    "home_own_num = 1 #home owner ship\n",
    "purpose = 5\n",
    "monthly_debt = 5000\n",
    "years_credit_history = 15\n",
    "month_delinq = 30 #month since last delinquent\n",
    "num_openAC = 5 #number of open accounts\n",
    "num_credit_prob = 1\n",
    "cur_creditBalance = 220000\n",
    "max_openCredit = 400000 #maximum open credit\n",
    "bankrupticies = 1\n",
    "taxLien = 1\n",
    "\n",
    "output = createDummy(loan_status, cur_loan_amount, term, annual_income, \n",
    "                    years_in_current_job, home_own_num, purpose, monthly_debt, years_credit_history, \n",
    "                    month_delinq, num_openAC, num_credit_prob, cur_creditBalance, \n",
    "                    max_openCredit, bankrupticies, taxLien)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the prediction\n",
    "getCategory(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all independent variables vs credit score\n",
    "for col in df.columns:\n",
    "    if (col != 'Credit Score'):\n",
    "        df.plot.scatter(x=col, y='Credit Score', c='DarkBlue')"
   ]
  },
  {
   "source": [
    "None of the graphs appear to reveal a linear relationship."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Select X and y columns\n",
    "y = df['Credit Score']\n",
    "X = df.drop(columns=['Credit Score',\n",
    "                     'Loan ID',\n",
    "                     'Customer ID',\n",
    "                     'Number of Credit Problems'])\n",
    "\n",
    "# Add constant row to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Train model and predict train/test sets\n",
    "model = sm.OLS(y_train,X_train).fit()\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearities between variables\n",
    "vif = {var_name: variance_inflation_factor(X_train.values, i) for var_name, i in zip(X_train.columns, range(X_train.shape[1]))}\n",
    "vif"
   ]
  },
  {
   "source": [
    "All VIF values are under 5 (excluding the intercept) implying no strong multicollinearities."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resid.plot.hist()\n",
    "plt.xlabel('residual')\n",
    "plt.title('Frequency of Residuals')\n",
    "plt.show()\n",
    "\n",
    "resid_analysis = pd.DataFrame(columns=['predicted value','residual'])\n",
    "resid_analysis['predicted value'] = model.predict(X_train)\n",
    "resid_analysis['residual'] = model.resid\n",
    "resid_analysis.plot.scatter(x='predicted value',y='residual',c='DarkBlue')\n",
    "plt.axhline(y=0, color='b', linestyle='-')\n",
    "plt.title('Predicted Value vs. Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print MSE values for train/test sets\n",
    "print(\"MSE for training set: \", mean_squared_error(y_train, y_pred_train))\n",
    "print(\"MSE for testing set: \", mean_squared_error(y_test, y_pred), \"\\n\")\n",
    "\n",
    "# Print R2 values for train/test sets\n",
    "print(\"R2 score for training set: \", r2_score(y_train, y_pred_train))\n",
    "print(\"R2 score for testing set: \", r2_score(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "source": [
    "At first glance, graphing the independent variables vs. the dependent variable (credit score) show no strong linear trends. Furthermore, the linear model developed has a low R2 around 0.20 and does not pass residual analysis either. Therefore, a linear model is not a good model for predicting credit score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}